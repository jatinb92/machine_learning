{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/jatin2055/elastic-net?scriptVersionId=258695464\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-28T12:30:33.255629Z","iopub.execute_input":"2025-08-28T12:30:33.255951Z","iopub.status.idle":"2025-08-28T12:30:33.261644Z","shell.execute_reply.started":"2025-08-28T12:30:33.255921Z","shell.execute_reply":"2025-08-28T12:30:33.260723Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.datasets import load_diabetes\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score, mean_squared_error","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T12:30:33.263407Z","iopub.execute_input":"2025-08-28T12:30:33.263773Z","iopub.status.idle":"2025-08-28T12:30:33.285301Z","shell.execute_reply.started":"2025-08-28T12:30:33.263749Z","shell.execute_reply":"2025-08-28T12:30:33.284236Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"X, y = load_diabetes(return_X_y=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T12:30:33.286328Z","iopub.execute_input":"2025-08-28T12:30:33.287122Z","iopub.status.idle":"2025-08-28T12:30:33.311338Z","shell.execute_reply.started":"2025-08-28T12:30:33.287022Z","shell.execute_reply":"2025-08-28T12:30:33.309912Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y , test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T12:30:33.312736Z","iopub.execute_input":"2025-08-28T12:30:33.313197Z","iopub.status.idle":"2025-08-28T12:30:33.331748Z","shell.execute_reply.started":"2025-08-28T12:30:33.313155Z","shell.execute_reply":"2025-08-28T12:30:33.330695Z"}},"outputs":[],"execution_count":42},{"cell_type":"markdown","source":"# Simple Linear Regression","metadata":{}},{"cell_type":"code","source":"lr = LinearRegression()\nlr.fit(X_train, y_train)\n\ny_pred = lr.predict(X_test)\n\nr2score = r2_score(y_test, y_pred)\nrmse = np.sqrt(mean_squared_error(y_test, y_pred))\nprint(r2score)\nprint(rmse)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T12:30:33.333853Z","iopub.execute_input":"2025-08-28T12:30:33.334197Z","iopub.status.idle":"2025-08-28T12:30:33.357364Z","shell.execute_reply.started":"2025-08-28T12:30:33.334168Z","shell.execute_reply":"2025-08-28T12:30:33.356458Z"}},"outputs":[{"name":"stdout","text":"0.4526027629719195\n53.85344583676593\n","output_type":"stream"}],"execution_count":43},{"cell_type":"markdown","source":"# Ridge Regression","metadata":{}},{"cell_type":"code","source":"alpha = 0.05 # tried 0.1, 0.2\nreg = Ridge(alpha=alpha)\n\nreg.fit(X_train, y_train)\n\nreg_y_pred = reg.predict(X_test)\n\nr2score = r2_score(y_test, reg_y_pred)\nrmse = np.sqrt(mean_squared_error(y_test, reg_y_pred))\nprint(r2score)\nprint(rmse)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T12:37:28.832603Z","iopub.execute_input":"2025-08-28T12:37:28.832881Z","iopub.status.idle":"2025-08-28T12:37:28.841968Z","shell.execute_reply.started":"2025-08-28T12:37:28.832862Z","shell.execute_reply":"2025-08-28T12:37:28.841035Z"}},"outputs":[{"name":"stdout","text":"0.4589982185720506\n53.5379261292692\n","output_type":"stream"}],"execution_count":78},{"cell_type":"markdown","source":"# Lasso Regression","metadata":{}},{"cell_type":"code","source":"alpha = 0.1 # tried 0.1, 0.2, 0.3 etc\nlas = Lasso(alpha=alpha)\n\nlas.fit(X_train, y_train)\n\nlas_y_pred = las.predict(X_test)\n\nl_r2score = r2_score(y_test, las_y_pred)\nl_rmse = np.sqrt(mean_squared_error(y_test, las_y_pred))\nprint(l_r2score)\nprint(l_rmse)\n\n#0.46113836892116755\n#53.431925783269534","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T12:33:19.880382Z","iopub.execute_input":"2025-08-28T12:33:19.880686Z","iopub.status.idle":"2025-08-28T12:33:19.891573Z","shell.execute_reply.started":"2025-08-28T12:33:19.880663Z","shell.execute_reply":"2025-08-28T12:33:19.890479Z"}},"outputs":[{"name":"stdout","text":"0.4718547867276227\n52.897953506442185\n","output_type":"stream"}],"execution_count":59},{"cell_type":"markdown","source":"# Elastic Net","metadata":{}},{"cell_type":"code","source":"alpha = 0.005 # tried 0.001, 0.0015, 0.002 etc\nl1_ratio = 0.9 # 90% ridge & 10% lasso\nen = ElasticNet(alpha=alpha, l1_ratio = l1_ratio)\n\nen.fit(X_train, y_train)\n\nen_y_pred = en.predict(X_test)\n\nen_r2score = r2_score(y_test, en_y_pred)\nen_rmse = np.sqrt(mean_squared_error(y_test, en_y_pred))\nprint(en_r2score)\nprint(en_rmse)\n\n# only ridge at 0.05 \n# 0.4589982185720506\n# 53.5379261292692","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T12:37:01.002825Z","iopub.execute_input":"2025-08-28T12:37:01.003205Z","iopub.status.idle":"2025-08-28T12:37:01.012518Z","shell.execute_reply.started":"2025-08-28T12:37:01.003118Z","shell.execute_reply":"2025-08-28T12:37:01.011485Z"}},"outputs":[{"name":"stdout","text":"0.46192536271651097\n53.39289353796021\n","output_type":"stream"}],"execution_count":77},{"cell_type":"markdown","source":"# All these regressors can be applied using SGDRegressors as well for using Stochastic Gradient Descent","metadata":{}}]}