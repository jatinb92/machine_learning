{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5196,"sourceType":"datasetVersion","datasetId":3147}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/jatin2055/classification-metrics?scriptVersionId=259566202\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T11:46:11.876395Z","iopub.execute_input":"2025-09-02T11:46:11.876698Z","iopub.status.idle":"2025-09-02T11:46:12.289954Z","shell.execute_reply.started":"2025-09-02T11:46:11.876675Z","shell.execute_reply":"2025-09-02T11:46:12.288749Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/mnist-digit-recognizer/train.csv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, classification_report\nfrom sklearn.datasets import make_classification\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T11:46:12.291529Z","iopub.execute_input":"2025-09-02T11:46:12.292416Z","iopub.status.idle":"2025-09-02T11:46:13.417283Z","shell.execute_reply.started":"2025-09-02T11:46:12.292386Z","shell.execute_reply":"2025-09-02T11:46:13.416324Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/mnist-digit-recognizer/train.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T11:46:13.418055Z","iopub.execute_input":"2025-09-02T11:46:13.418535Z","iopub.status.idle":"2025-09-02T11:46:16.883921Z","shell.execute_reply.started":"2025-09-02T11:46:13.4185Z","shell.execute_reply":"2025-09-02T11:46:16.882966Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T11:46:16.886201Z","iopub.execute_input":"2025-09-02T11:46:16.88649Z","iopub.status.idle":"2025-09-02T11:46:16.915116Z","shell.execute_reply.started":"2025-09-02T11:46:16.886468Z","shell.execute_reply":"2025-09-02T11:46:16.91434Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n0      1       0       0       0       0       0       0       0       0   \n1      0       0       0       0       0       0       0       0       0   \n2      1       0       0       0       0       0       0       0       0   \n3      4       0       0       0       0       0       0       0       0   \n4      0       0       0       0       0       0       0       0       0   \n\n   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n0       0  ...         0         0         0         0         0         0   \n1       0  ...         0         0         0         0         0         0   \n2       0  ...         0         0         0         0         0         0   \n3       0  ...         0         0         0         0         0         0   \n4       0  ...         0         0         0         0         0         0   \n\n   pixel780  pixel781  pixel782  pixel783  \n0         0         0         0         0  \n1         0         0         0         0  \n2         0         0         0         0  \n3         0         0         0         0  \n4         0         0         0         0  \n\n[5 rows x 785 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 785 columns</p>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"X = df.iloc[:,1:]\ny = df.iloc[:, 0]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T11:46:16.916033Z","iopub.execute_input":"2025-09-02T11:46:16.916338Z","iopub.status.idle":"2025-09-02T11:46:17.182909Z","shell.execute_reply.started":"2025-09-02T11:46:16.916308Z","shell.execute_reply":"2025-09-02T11:46:17.181788Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"logr = LogisticRegression(multi_class='multinomial') # softmax regression\ndct = DecisionTreeClassifier()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T11:46:17.183958Z","iopub.execute_input":"2025-09-02T11:46:17.184262Z","iopub.status.idle":"2025-09-02T11:46:17.189199Z","shell.execute_reply.started":"2025-09-02T11:46:17.184239Z","shell.execute_reply":"2025-09-02T11:46:17.188233Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"logr.fit(X_train, y_train)\ndct.fit(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T11:46:17.190203Z","iopub.execute_input":"2025-09-02T11:46:17.190429Z","iopub.status.idle":"2025-09-02T11:46:42.148304Z","shell.execute_reply.started":"2025-09-02T11:46:17.190409Z","shell.execute_reply":"2025-09-02T11:46:42.147303Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"DecisionTreeClassifier()","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"y_pred_logr = logr.predict(X_test)\ny_pred_dct = dct.predict(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T11:46:42.14941Z","iopub.execute_input":"2025-09-02T11:46:42.149726Z","iopub.status.idle":"2025-09-02T11:46:42.218897Z","shell.execute_reply.started":"2025-09-02T11:46:42.149705Z","shell.execute_reply":"2025-09-02T11:46:42.217837Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# Accuracy Score ","metadata":{}},{"cell_type":"code","source":"print(f\"accuracy_score logistic : {accuracy_score(y_test, y_pred_logr)}\")\nprint(f\"accuracy_score dct : {accuracy_score(y_test, y_pred_dct)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T11:46:42.220013Z","iopub.execute_input":"2025-09-02T11:46:42.220318Z","iopub.status.idle":"2025-09-02T11:46:42.229136Z","shell.execute_reply.started":"2025-09-02T11:46:42.220296Z","shell.execute_reply":"2025-09-02T11:46:42.228042Z"}},"outputs":[{"name":"stdout","text":"accuracy_score logistic : 0.9183333333333333\naccuracy_score dct : 0.8558333333333333\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"print(y_test[:10])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T11:47:11.58666Z","iopub.execute_input":"2025-09-02T11:47:11.587067Z","iopub.status.idle":"2025-09-02T11:47:11.593778Z","shell.execute_reply.started":"2025-09-02T11:47:11.587042Z","shell.execute_reply":"2025-09-02T11:47:11.592424Z"}},"outputs":[{"name":"stdout","text":"5457     8\n38509    1\n25536    9\n31803    9\n39863    8\n30639    6\n12986    2\n41067    2\n30743    7\n6839     1\nName: label, dtype: int64\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"print(y_pred_logr[:10])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T11:47:29.645304Z","iopub.execute_input":"2025-09-02T11:47:29.646195Z","iopub.status.idle":"2025-09-02T11:47:29.651917Z","shell.execute_reply.started":"2025-09-02T11:47:29.646146Z","shell.execute_reply":"2025-09-02T11:47:29.650602Z"}},"outputs":[{"name":"stdout","text":"[8 1 9 9 8 6 2 2 7 1]\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"# Precision ","metadata":{}},{"cell_type":"code","source":"print(f\"weighted precision_score logistic : {precision_score(y_test, y_pred_logr, average='weighted')}\")\nprint(f\"weighted precision_score dct : {precision_score(y_test, y_pred_dct, average='weighted')}\")\n\nprint(f\"macro precision_score logistic : {precision_score(y_test, y_pred_logr, average='macro')}\")\nprint(f\"macro precision_score dct : {precision_score(y_test, y_pred_dct, average='macro')}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T11:46:42.246862Z","iopub.execute_input":"2025-09-02T11:46:42.24723Z","iopub.status.idle":"2025-09-02T11:46:42.290187Z","shell.execute_reply.started":"2025-09-02T11:46:42.247208Z","shell.execute_reply":"2025-09-02T11:46:42.289319Z"}},"outputs":[{"name":"stdout","text":"weighted precision_score logistic : 0.918193813333413\nweighted precision_score dct : 0.8557018775007045\nmacro precision_score logistic : 0.9172944292527226\nmacro precision_score dct : 0.8542647371524206\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"# Recall","metadata":{}},{"cell_type":"code","source":"print(f\"weighted recall_score logistic : {recall_score(y_test, y_pred_logr, average='weighted')}\")\nprint(f\"weighted recall_score dct : {recall_score(y_test, y_pred_dct, average='weighted')}\")\n\nprint(f\"macro recall_score logistic : {recall_score(y_test, y_pred_logr, average='macro')}\")\nprint(f\"macro recall_score dct : {recall_score(y_test, y_pred_dct, average='macro')}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T11:46:42.291171Z","iopub.execute_input":"2025-09-02T11:46:42.291443Z","iopub.status.idle":"2025-09-02T11:46:42.321237Z","shell.execute_reply.started":"2025-09-02T11:46:42.291418Z","shell.execute_reply":"2025-09-02T11:46:42.320393Z"}},"outputs":[{"name":"stdout","text":"weighted recall_score logistic : 0.9183333333333333\nweighted recall_score dct : 0.8558333333333333\nmacro recall_score logistic : 0.9178201145023271\nmacro recall_score dct : 0.8547794886138561\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"# F1 score","metadata":{}},{"cell_type":"code","source":"print(f\"weighted f1_score logistic : {f1_score(y_test, y_pred_logr, average='weighted')}\")\nprint(f\"weighted f1_score dct : {f1_score(y_test, y_pred_dct, average='weighted')}\")\n\nprint(f\"macro f1_score logistic : {f1_score(y_test, y_pred_logr, average='macro')}\")\nprint(f\"macro f1_score dct : {f1_score(y_test, y_pred_dct, average='macro')}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T11:46:42.322171Z","iopub.execute_input":"2025-09-02T11:46:42.322464Z","iopub.status.idle":"2025-09-02T11:46:42.354Z","shell.execute_reply.started":"2025-09-02T11:46:42.322438Z","shell.execute_reply":"2025-09-02T11:46:42.353047Z"}},"outputs":[{"name":"stdout","text":"weighted f1_score logistic : 0.9182097218284928\nweighted f1_score dct : 0.855715394942391\nmacro f1_score logistic : 0.9175034172883801\nmacro f1_score dct : 0.8544713470141939\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"# Combined Classification Report\n\nThis provides weighted & macro(avg) - precision, recall and f1_score","metadata":{}},{"cell_type":"code","source":"print(\"confusion_matrix logistic : \")\nprint(classification_report(y_test, y_pred_logr))\n\nprint(\"confusion_matrix dct : \")\nprint(classification_report(y_test, y_pred_dct))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T11:46:42.354967Z","iopub.execute_input":"2025-09-02T11:46:42.35525Z","iopub.status.idle":"2025-09-02T11:46:42.40741Z","shell.execute_reply.started":"2025-09-02T11:46:42.355229Z","shell.execute_reply":"2025-09-02T11:46:42.40651Z"}},"outputs":[{"name":"stdout","text":"confusion_matrix logistic : \n              precision    recall  f1-score   support\n\n           0       0.96      0.96      0.96       816\n           1       0.96      0.98      0.97       909\n           2       0.92      0.90      0.91       846\n           3       0.90      0.89      0.89       937\n           4       0.93      0.93      0.93       839\n           5       0.87      0.87      0.87       702\n           6       0.93      0.96      0.95       785\n           7       0.93      0.92      0.93       893\n           8       0.88      0.88      0.88       835\n           9       0.90      0.90      0.90       838\n\n    accuracy                           0.92      8400\n   macro avg       0.92      0.92      0.92      8400\nweighted avg       0.92      0.92      0.92      8400\n\nconfusion_matrix dct : \n              precision    recall  f1-score   support\n\n           0       0.91      0.91      0.91       816\n           1       0.92      0.94      0.93       909\n           2       0.82      0.81      0.82       846\n           3       0.83      0.81      0.82       937\n           4       0.85      0.86      0.86       839\n           5       0.78      0.80      0.79       702\n           6       0.88      0.89      0.89       785\n           7       0.91      0.89      0.90       893\n           8       0.80      0.79      0.79       835\n           9       0.84      0.84      0.84       838\n\n    accuracy                           0.86      8400\n   macro avg       0.85      0.85      0.85      8400\nweighted avg       0.86      0.86      0.86      8400\n\n","output_type":"stream"}],"execution_count":15}]}